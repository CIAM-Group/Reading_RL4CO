{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"try.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14ebn4d1b853qsihRk8JdnzRwSeQu-PKX","authorship_tag":"ABX9TyMeHH6AXEfX0V1EErudm/Hb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"n5-W1KOxbsS4","executionInfo":{"status":"ok","timestamp":1635477261762,"user_tz":-480,"elapsed":27008,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["import torch\n","import itertools\n","import numpy as np\n","import torch.nn as nn\n","from tqdm import tqdm\n","import torch.optim as optim\n","from torch.nn import Parameter\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS-EACGGsxch","executionInfo":{"status":"ok","timestamp":1635477269288,"user_tz":-480,"elapsed":436,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["# 辅助函数，用于生成训练样例的最优解\n","# 来自 https://gist.github.com/mlalevic/6222750\n","def tsp_opt(points):\n","    \"\"\"\n","    O(2^n*n^2)\n","    :param points: List of (x, y) points\n","    :return: Optimal solution\n","    \"\"\"\n","\n","    def length(x_coord, y_coord):\n","        return np.linalg.norm(np.asarray(x_coord) - np.asarray(y_coord))\n","\n","    # Calculate all lengths\n","    all_distances = [[length(x, y) for y in points] for x in points]\n","    # Initial value - just distance from 0 to every other point + keep the track of edges\n","    A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1]) for idx, dist in enumerate(all_distances[0][1:])}\n","    cnt = len(points)\n","    for m in range(2, cnt):\n","        B = {}\n","        for S in [frozenset(C) | {0} for C in itertools.combinations(range(1, cnt), m)]:\n","            for j in S - {0}:\n","                # This will use 0th index of tuple for ordering, the same as if key=itemgetter(0) used\n","                B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j], A[(S-{j}, k)][1] + [j])\n","                                 for k in S if k != 0 and k != j])\n","        A = B\n","    res = min([(A[d][0] + all_distances[0][d[1]], A[d][1]) for d in iter(A)])\n","    return np.asarray(res[1])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9cuSN2paGVL","executionInfo":{"status":"ok","timestamp":1635477271128,"user_tz":-480,"elapsed":13,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["# 首先，编写生成训练集的DATASET\n","\n","class TSP_Dataset(Dataset):\n","    def __init__(self, data_size, citys_size):\n","        \"\"\"\n","        data_size: int, 训练集大小\n","        citys_size: int, 每个训练数据包含多少城市，\n","        \"\"\"\n","        super(TSP_Dataset, self).__init__()\n","        self.data_size = data_size\n","        self.citys_size = citys_size\n","        self.data = self.get_data()\n","    \n","    def __len__(self):\n","        return self.data_size\n","\n","    def __getitem__(self, idx):\n","        return {'Point': self.data['Point'][idx], 'Slove':self.data['Slove'][idx]}\n","\n","    def get_data(self):\n","        \"\"\"\n","        随生成数据\n","        \"\"\"\n","        point = np.random.rand(self.data_size, self.citys_size, 2)\n","        slove = [tsp_opt(citys) for citys in point]\n","        return dict(Point = point, Slove = slove)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZxEvjVM7GS--","executionInfo":{"status":"ok","timestamp":1635477272923,"user_tz":-480,"elapsed":31,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["# 然后是模型\n","\n","# Encoder Model\n","\n","class Encoder(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, num_layers, dropout, bidirectional):\n","        super(Encoder, self).__init__()\n","\n","        # 用于接下来初始化h0, c0\n","        self.num_layers = num_layers*2 if bidirectional else num_layers\n","\n","        #为了维持不管是否BRNN，输出的hidden_size 都等于hidden_dim, 这里的self.hidden_dim意味着建立LSTM的hidden_dim\n","        self.hidden_dim = hidden_dim//2 if bidirectional else hidden_dim\n","\n","        self.lstm = nn.LSTM(\n","            input_size = embedding_dim, \n","            hidden_size = self.hidden_dim, \n","            num_layers = num_layers, \n","            batch_first = True,\n","            dropout = dropout, \n","            bidirectional = bidirectional)\n","        \n","        self.h0 = Parameter(torch.zeros(1), requires_grad=False)\n","        self.c0 = Parameter(torch.zeros(1), requires_grad=False)\n","\n","    def forward(self, embedded_inputs):\n","\n","        batch_size = embedded_inputs.size(0)\n","        h_0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.num_layers,\n","                                                      batch_size,\n","                                                      self.hidden_dim)\n","        c_0 = self.c0.unsqueeze(0).unsqueeze(0).repeat(self.num_layers,\n","                                                      batch_size,\n","                                                      self.hidden_dim)\n","\n","        output, (h_n, c_n) = self.lstm(embedded_inputs, (h_0, c_0))    \n","        return output, (h_n, c_n)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"krO8KyjQI3Fq","executionInfo":{"status":"ok","timestamp":1635477274743,"user_tz":-480,"elapsed":16,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["# Attention Layer\n","\n","class Attention(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(Attention, self).__init__()\n","\n","        self.h_t_linear = nn.Linear(hidden_dim, hidden_dim)\n","        self.h_s_linear = nn.Conv1d(hidden_dim, hidden_dim, 1, 1)\n","\n","        # F.tanh 被 deprecated 了，要用nn.Tanh\n","        # https://discuss.pytorch.org/t/torch-tanh-vs-torch-nn-functional-tanh/15897\n","        # https://stackoverflow.com/questions/56723486/why-arent-torch-functional-sigmoid-and-torch-nn-functional-relu-deprecated-like\n","        self.tanh = nn.Tanh()\n","        self.softmax = nn.Softmax()\n","\n","        self.V = Parameter(torch.FloatTensor(hidden_dim), requires_grad=True)\n","        # 不要用uniform_，那是就地操作\n","        nn.init.uniform(self.V, -1, 1)\n","        # 不要用alpha[visted] = float('-inf'),好像也是就地操作？\n","        # self.inf = self._inf.unsqueeze(1).expand(*mask_size) 是为了避免就地操作，避免a = a的情况\n","        self._inf = Parameter(torch.FloatTensor([float('-inf')]), requires_grad=False)\n","\n","    def forward(self, h_s, h_t, visted):\n","        \"\"\"\n","        h_s = encoder_output （N, L, Hidden）\n","        h_t = h_t   (N, Hidden)\n","        visted :访问过的城市TrueFalse Tensor (N, L)就是N个L\n","        \"\"\"\n","        # score = V * tanh(W[h_s, h_t])\n","        \n","        #(N, Hidden, L)\n","        h_s_ = self.h_s_linear(h_s.permute(0, 2, 1))\n","        #(N, Hidden, L)\n","        h_t_ = self.h_t_linear(h_t).unsqueeze(2).expand(-1, -1, h_s_.size(2))\n","\n","        # V 需要是（N, 1, Hidden） 乘出来是（N, 1, L）, 再经过softmax就是概率\n","        V = self.V.unsqueeze(0).unsqueeze(0).expand(h_s_.size(0), -1, -1)\n","        # (N, L)\n","        alpha = torch.bmm(V, self.tanh(h_s_ + h_t_)).squeeze(1)\n","\n","        # 将访问过的City alpha 变为-inf再softmax\n","        self.inf = self._inf.unsqueeze(1).expand(alpha.size(0), alpha.size(1))\n","        # 不能  alpha[visted] = float('-inf')  谨防就地操作\n","        if len(alpha[visted]) > 0:\n","            alpha[visted] = self.inf[visted]\n","\n","        alpha_ = self.softmax(alpha)\n","        # c_t = h_s * alpha_ (N, Hidden) \n","        # 找到了，是attention层的内容\n","        c_t = torch.bmm(h_s_, alpha_.unsqueeze(2)).squeeze(2)\n","        return c_t, alpha_\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nF-GlGpeUXf","executionInfo":{"status":"ok","timestamp":1635477276270,"user_tz":-480,"elapsed":14,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["# Decoder Model\n","\n","class Decoder(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim):\n","        super(Decoder, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.input0 = Parameter(torch.FloatTensor(embedding_dim), requires_grad=False)\n","        # decoder的input0初始化为[-1, 1]随机数 (batch, embedding_dim)\n","        nn.init.uniform_(self.input0, -1, 1)\n","\n","        self.i2h = nn.Linear(embedding_dim, 4*hidden_dim)\n","        self.h2h = nn.Linear(hidden_dim, 4*hidden_dim)\n","\n","        self.att = Attention(hidden_dim)\n","\n","        # 为 0（False）代表没被访问过 \n","        self.visted = Parameter(torch.zeros(1), requires_grad=False) \n","\n","        # h ̃t = tanh(Wc[c_t; h_t])\n","        self.Wc = nn.Linear(2*hidden_dim, hidden_dim)\n","\n","        # 辅助判断是否visted\n","        self.help_visted = Parameter(torch.zeros(1), requires_grad=False)\n","\n","        self.sigmoid =  nn.Sigmoid()\n","        self.tanh =  nn.Tanh()\n","\n","\n","    def forward(self, embedded_inputs, decoder_h_0, decoder_c_0, encoder_output):\n","        batch_size = embedded_inputs.size(0)\n","        input_length = embedded_inputs.size(1)\n","\n","        # (N, embedding)\n","        decoder_input = self.input0.unsqueeze(0).expand(batch_size, -1)\n","        \n","        # 初始 h, c 为encoder最后一个状态\n","        decoder_h = decoder_h_0\n","        decoder_c = decoder_c_0\n","\n","        # (N, L)\n","        visted = self.visted.unsqueeze(0).expand(batch_size, input_length)\n","\n","        # (N, L)\n","        help_visted = self.help_visted.repeat(input_length)\n","        for i in range(input_length):\n","            help_visted.data[i] = i\n","        help_visted = help_visted.unsqueeze(0).expand(batch_size, -1).long()\n","\n","\n","        # 最后要返回城市序列 pointers 和 每一级的output = alpha\n","        outputs = []\n","        pointers = []\n","\n","        def step(x, h, c):\n","            \"\"\"\n","            模拟一个lstm cell，然后增加一个layer层\n","            x: (N, embeding_dim)\n","            h: (N, Hidden)\n","            c: (N, Hidden)\n","            \"\"\" \n","            # (N, 4 * Hidden)\n","            gates = self.i2h(x) + self.h2h(h)\n","            # (N, Hidden)\n","            input, forget, cell, out = gates.chunk(4,1)\n","\n","            forget = self.sigmoid(forget)\n","            input = self.sigmoid(input)\n","            cell = self.tanh(cell)\n","            out = self.sigmoid(out)\n","\n","            c_t = (c * forget) + (input * cell)\n","            # (N, Hidden)\n","            h_t = self.tanh(c_t) * out\n","\n","            # h_s = encoder_output, h_t, visited 进入 attn 层， 获得c_t(N, Hidden), alpha (N, L)\n","            c_t, alpha = self.att(encoder_output, h_t, torch.eq(visted, 1))\n","            hidden_t = self.tanh(self.Wc(torch.cat((c_t, h_t), 1)))\n","\n","            return hidden_t, c_t, alpha\n","        \n","        for _ in range(input_length):\n","            decoder_h, decoder_c, alpha = step(decoder_input, decoder_h, decoder_c)\n","            # 将访问过的alpha 置 0,然后求最大的alpha的坐标 indices(N)  \n","            # 不能alpha[torch.eq(visted, 1)] = 0，谨防就地操作\n","            alpha_ = alpha * (1 - visted)\n","            val, indices = alpha_.max(1)\n","            # alpha_ (N, L) \n","            # 求得该次应该访问的城市，用indices(N),help_visted(N, L)更新visted (N,L),\n","            # tmp (N, L)\n","            tmp  = (help_visted == (indices.unsqueeze(1).expand(-1, input_length)))\n","            visted = 1 -  (1 - visted) * (1 - tmp.float())\n","\n","            # 通过indeices(N), embedding_inputs(N, L, embedding_dim) 获得下一次的输入decoder_input(N, embedding)\n","            decoder_input = embedded_inputs[tmp.unsqueeze(2).expand(-1, -1, self.embedding_dim)].view(batch_size, self.embedding_dim)\n","\n","            # 为了cat合并出想要的效果，这里需要做一些处理\n","            outputs.append(alpha_.unsqueeze(0))\n","            pointers.append(indices.unsqueeze(1))\n","        \n","        # (N, L, L（概率数组）) 表示每次的输出的alpha数组(L)， 每个aplha代表该次预测的各城市的概率\n","        outputs = torch.cat(outputs).permute(1, 0, 2)\n","        # (N, L) 表示一个最优解\n","        pointers = torch.cat(pointers, 1)\n","\n","        return (outputs, pointers), (decoder_h, decoder_c)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5brY3us3eWU7","executionInfo":{"status":"ok","timestamp":1635477278020,"user_tz":-480,"elapsed":18,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["class PtrNet(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, num_layers, dropout, bidirectional):\n","        \"\"\"\n","        hidden_dim : encoder与decoder共用，隐状态feature数\n","        num_layers : encoder使用，拥用于init LSTM, 代表堆叠层数\n","        dropout : encoder使用，拥用于init LSTM, 代表丢弃数\n","        bidirectional : encoder使用，拥用于init LSTM, 代表是否双向输入\n","        \"\"\"\n","        super(PtrNet, self).__init__()\n","        self.bidir = bidirectional\n","        self.embedding = nn.Linear(2, embedding_dim)\n","        self.encoder = Encoder(embedding_dim, hidden_dim, num_layers, dropout, bidirectional)\n","        self.decoder = Decoder(embedding_dim, hidden_dim)\n","    \n","    def forward(self, inputs):\n","        \"\"\" \n","        inputs：(batch_size, seq_length, 2) 全部城市的坐标\n","        \"\"\"\n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","        \n","        # 对输入的数据进行embedding编码\n","        # (batch_size, seq_length, embedding_dim)\n","        embedded_inputs = self.embedding(  inputs.view(batch_size * seq_length, -1)   ).view(batch_size, seq_length, -1)\n","\n","        #将embedded_inputs送入 encoder 中\n","        encoder_output, (encoder_h_n, encoder_c_n) = self.encoder(embedded_inputs)\n","\n","        # decoder 需要的有：\n","        # encoder_output, (所有encoder的隐状态，用于传入attention)\n","        # decoder_h_0 = encoder_h_n, decoder_c_0 = encoder_c_n, \n","        # seq_length循环次数,\n","        # embedded_inputs, 作为每次选出的城市，输入下一次循环中\n","\n","        # embedded_inputs, encoder_h_n, encoder_c_n, encoder_output, seq_length\n","        if self.bidir:\n","            decoder_h = torch.cat( (encoder_h_n[-1],encoder_h_n[-2]), dim=-1)\n","            decoder_c = torch.cat( (encoder_c_n[-1],encoder_c_n[-2]), dim=-1)\n","        else:\n","            decoder_h = encoder_h_n[-1]\n","            decoder_c = encoder_c_n[-1]\n","\n","        (outputs, pointers), (decoder_h, decoder_c) = self.decoder(embedded_inputs,\n","                                                           decoder_h, \n","                                                           decoder_c,\n","                                                           encoder_output)\n","        return  outputs, pointers\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"wolk3DU5FQb-","executionInfo":{"status":"ok","timestamp":1635479947969,"user_tz":-480,"elapsed":413,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["train_size = 100000 # 训练集大小,每次epoch进行train_size个数据的训练\n","seq_length = 5  # 单个训练数据的城市数目"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-PT7TQS5qY2","executionInfo":{"status":"ok","timestamp":1635479983347,"user_tz":-480,"elapsed":34034,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["myDataset = TSP_Dataset(train_size , seq_length)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrTDsgywFXtl","executionInfo":{"status":"ok","timestamp":1635480041217,"user_tz":-480,"elapsed":385,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["batch_size = 512  # batch大小，每epoch进行 train_size/batch_size 次batch  "],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"ADO2pxOujHj1","executionInfo":{"status":"ok","timestamp":1635480042868,"user_tz":-480,"elapsed":9,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["myDataloader = DataLoader(dataset = myDataset, batch_size = batch_size, shuffle = True, num_workers = 2)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_OmNhwDFc38","executionInfo":{"status":"ok","timestamp":1635486845341,"user_tz":-480,"elapsed":434,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["embedding_dim = 128  \n","hidden_dim = 512\n","num_layers = 4\n","dropout = 0.001\n","bidirectional = True "],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8hSy3L4FbIn","executionInfo":{"status":"ok","timestamp":1635486850112,"user_tz":-480,"elapsed":455,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}},"outputId":"102a8a94-8057-4232-a13d-44ebbbe7553e"},"source":["mymodel = PtrNet(embedding_dim, hidden_dim, num_layers, dropout, bidirectional)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n"]}]},{"cell_type":"code","metadata":{"id":"DnoW0rLIFl-h","executionInfo":{"status":"ok","timestamp":1635486857662,"user_tz":-480,"elapsed":467,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["lr = 0.0005"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dds06xD0OYQB","executionInfo":{"status":"ok","timestamp":1635486859133,"user_tz":-480,"elapsed":6,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["CCE = torch.nn.CrossEntropyLoss()\n","mymodel_optim = optim.Adam(filter(lambda p: p.requires_grad, mymodel.parameters()), lr=lr)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMEz8kX2FmmL","executionInfo":{"status":"ok","timestamp":1635486860844,"user_tz":-480,"elapsed":5,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["num_epochs = 7  # epoch数"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMXrx1lbxRWo","executionInfo":{"status":"ok","timestamp":1635491548191,"user_tz":-480,"elapsed":378043,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}},"outputId":"7888443f-c559-45b0-ede9-e21d2ab578a2"},"source":["# 开始训练\n","\n","\n","losses = []\n","# writer = SummaryWriter()\n","\n","for epoch in range(num_epochs):\n","    batch_loss = []\n","    iterator = tqdm(myDataloader, unit='Batch')\n","    for i, item in enumerate(iterator):\n","        iterator.set_description('Batch %i/%i' % (epoch+1, num_epochs))\n","\n","        # torch.autograd.set_detect_anomaly(True)\n","        outputs, pointers = mymodel(item['Point'].float())\n","        # outputs (N, L, L)\n","        # item['Slove'] (N, L)\n","\n","\n","        # (N*L, L)\n","        outputs  = outputs.contiguous().view(-1, outputs.size()[-1])\n","        # (N*L)\n","        target = item['Slove'].view(-1)\n","        loss = CCE(outputs, target)\n","        \n","        mymodel_optim.zero_grad()\n","        loss.backward()\n","        mymodel_optim.step()\n","\n","        losses.append(loss.data.item())\n","        batch_loss.append(loss.data.item())\n","        iterator.set_postfix(loss='{}'.format(loss.data.item()))\n","\n","    iterator.set_postfix(loss=np.average(batch_loss))\n","    # writer.add_scalar('Loss/train', np.average(batch_loss), epoch)\n","\n","# writer.close()"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["Batch 1/7:   0%|          | 0/196 [00:00<?, ?Batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","Batch 1/7: 100%|██████████| 196/196 [08:48<00:00,  2.70s/Batch, loss=1.400560736656189]\n","Batch 2/7: 100%|██████████| 196/196 [10:34<00:00,  3.24s/Batch, loss=1.3110350370407104]\n","Batch 3/7: 100%|██████████| 196/196 [09:24<00:00,  2.88s/Batch, loss=1.276998519897461]\n","Batch 4/7: 100%|██████████| 196/196 [12:48<00:00,  3.92s/Batch, loss=1.2100845575332642]\n","Batch 5/7: 100%|██████████| 196/196 [12:17<00:00,  3.76s/Batch, loss=1.1762974262237549]\n","Batch 6/7: 100%|██████████| 196/196 [12:10<00:00,  3.73s/Batch, loss=1.1811286211013794]\n","Batch 7/7: 100%|██████████| 196/196 [12:01<00:00,  3.68s/Batch, loss=1.1782735586166382]\n"]}]},{"cell_type":"code","metadata":{"id":"lMYFzdgLhDc1","executionInfo":{"status":"ok","timestamp":1635478840154,"user_tz":-480,"elapsed":431,"user":{"displayName":"Han Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPi2bJ8SvnWL_kN8arLrSH7aHZ9ewWzGdz4o-Y=s64","userId":"07315305410615803184"}}},"source":["%load_ext tensorboard"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJcU2Ohe1IFH"},"source":["%tensorboard --logdir '/content/runs/Oct29_03-30-08_287f258c494c'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yxvZI62vcIEd"},"source":["按照参考代码中的预设跑出来的结果\n","```python\n","train_size = 10000 # 训练集大小,每次epoch进行train_size个数据的训练\n","seq_length = 5  # 单个训练数据的城市数目\n","batch_size = 256  # batch大小，每epoch进行 train_size/batch_size 次batch  \n","embedding_dim = 128  \n","hidden_dim = 512\n","num_layers = 2\n","dropout = 0.\n","bidirectional = True \n","lr = 0.0001\n","num_epochs = 10  # epoch数\n","\n","Batch 1/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.5213171243667603]\n","Batch 2/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.4382966756820679]\n","Batch 3/10: 100%|██████████| 40/40 [00:37<00:00,  1.05Batch/s, loss=1.4567874670028687]\n","Batch 4/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.4119609594345093]\n","Batch 5/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.426945686340332]\n","Batch 6/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.4063466787338257]\n","Batch 7/10: 100%|██████████| 40/40 [00:37<00:00,  1.05Batch/s, loss=1.3852460384368896]\n","Batch 8/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.3605930805206299]\n","Batch 9/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.3718546628952026]\n","Batch 10/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.2640124559402466]\n","```"]},{"cell_type":"markdown","metadata":{"id":"EfZiW0FvcLsB"},"source":["和上次比调大了lr，loss降低了一点点\n","\n","```python\n","train_size = 10000 # 训练集大小,每次epoch进行train_size个数据的训练\n","seq_length = 5  # 单个训练数据的城市数目\n","batch_size = 256  # batch大小，每epoch进行 train_size/batch_size 次batch  \n","embedding_dim = 128  \n","hidden_dim = 512\n","num_layers = 2\n","dropout = 0.\n","bidirectional = True \n","lr = 0.001\n","num_epochs = 10  # epoch数\n","\n","\n","Batch 1/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.4535272121429443]\n","Batch 2/10: 100%|██████████| 40/40 [00:38<00:00,  1.04Batch/s, loss=1.4366843700408936]\n","Batch 3/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.2903785705566406]\n","Batch 4/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.3250709772109985]\n","Batch 5/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.2955352067947388]\n","Batch 6/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.2900669574737549]\n","Batch 7/10: 100%|██████████| 40/40 [00:37<00:00,  1.06Batch/s, loss=1.2359356880187988]\n","Batch 8/10: 100%|██████████| 40/40 [00:37<00:00,  1.05Batch/s, loss=1.2447574138641357]\n","Batch 9/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.2044010162353516]\n","Batch 10/10: 100%|██████████| 40/40 [00:38<00:00,  1.05Batch/s, loss=1.2382856607437134]\n","```"]},{"cell_type":"markdown","metadata":{"id":"fjcN38ckmNva"},"source":["增加了训练集size,loss降低还算明显,运行时长853s\n","\n","```python\n","train_size = 100000 # 训练集大小,每次epoch进行train_size个数据的训练\n","seq_length = 5  # 单个训练数据的城市数目\n","batch_size = 512  # batch大小，每epoch进行 train_size/batch_size 次batch  \n","embedding_dim = 128  \n","hidden_dim = 512\n","num_layers = 2\n","dropout = 0.\n","bidirectional = True \n","lr = 0.0005\n","num_epochs = 10  # epoch数\n","\n","Batch 1/10: 100%|██████████| 196/196 [05:59<00:00,  1.83s/Batch, loss=1.3405646085739136]\n","Batch 2/10: 100%|██████████| 196/196 [06:07<00:00,  1.87s/Batch, loss=1.2688865661621094]\n","Batch 3/10: 100%|██████████| 196/196 [07:22<00:00,  2.26s/Batch, loss=1.2330338954925537]\n","Batch 4/10: 100%|██████████| 196/196 [09:54<00:00,  3.03s/Batch, loss=1.1934809684753418]\n","Batch 5/10: 100%|██████████| 196/196 [10:51<00:00,  3.32s/Batch, loss=1.2616503238677979]\n","Batch 6/10: 100%|██████████| 196/196 [10:45<00:00,  3.30s/Batch, loss=1.1770641803741455]\n","Batch 7/10: 100%|██████████| 196/196 [10:49<00:00,  3.32s/Batch, loss=1.1408429145812988]\n","Batch 8/10: 100%|██████████| 196/196 [10:58<00:00,  3.36s/Batch, loss=1.155600666999817]\n","Batch 9/10: 100%|██████████| 196/196 [10:54<00:00,  3.34s/Batch, loss=1.1500990390777588]\n","Batch 10/10: 100%|██████████| 196/196 [10:57<00:00,  3.35s/Batch, loss=1.1630727052688599]\n","\n","```"]},{"cell_type":"code","metadata":{"id":"LPDJX8811yrX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGhB9YI_LqFk"},"source":[""],"execution_count":null,"outputs":[]}]}